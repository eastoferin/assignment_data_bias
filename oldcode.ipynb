{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRTBBETaSfbk",
        "outputId": "3d4f3953-baec-4f2b-a563-640e3b2e4328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 10, 'score': {'value': 0.68408644, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.68408644, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n"
          ]
        }
      ],
      "source": [
        "from googleapiclient import discovery\n",
        "import json\n",
        "\n",
        "API_KEY = 'AIzaSyC0Sqaou4IUy22wHQxuMjb1uc_fzgaAdnY'\n",
        "\n",
        "client = discovery.build(\n",
        "  \"commentanalyzer\",\n",
        "  \"v1alpha1\",\n",
        "  developerKey=API_KEY,\n",
        "  discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
        "  static_discovery=False,\n",
        ")\n",
        "\n",
        "analyze_request = {\n",
        "  'comment': { 'text': 'i hate you' },\n",
        "  'requestedAttributes': {'TOXICITY': {}}\n",
        "}\n",
        "\n",
        "response = client.comments().analyze(body=analyze_request).execute()\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the API gives scores between 0 and 1. We can set the threshold to 0.5 and consider anything above 0.5 as toxic and below 0.5 as non toxic.\n"
      ],
      "metadata": {
        "id": "2xDaMRDytW_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "My Hypothesis:\n",
        "I believe that Perspective will be less able to detect toxicity from comments which incorporate British slang insults rather than common American ones. I think it will make more mistakes with comments in this category.\n",
        "\n",
        "Test set of statements\n",
        "\n",
        "American Insults:\n",
        "\n",
        "1. You're such an asshole.\n",
        "2. What a complete idiot.\n",
        "3. That makes you a thot.\n",
        "4. I don't know why you're a dickhead.\n",
        "5. This proves you're only meant for blue collar work.\n",
        "\n",
        "British Insults:\n",
        "\n",
        "1. You're such a tosser.\n",
        "2. What a complete wanker.\n",
        "3. That makes you a slag.\n",
        "4. I don't know why you're a knob head.\n",
        "5. This proves you're just a wazzock.\n",
        "\n",
        "Each British phrase corresponds to the American term used for the same listed number. They're effectively synonyms."
      ],
      "metadata": {
        "id": "6Of8GtMt01i1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_request = {\n",
        "  'comment': { 'text': 'You\\'re such an asshole.' },\n",
        "  'requestedAttributes': {'TOXICITY': {}}\n",
        "}\n",
        "\n",
        "response = client.comments().analyze(body=analyze_request).execute()\n",
        "print(response)\n",
        "\n",
        "analyze_request = {\n",
        "  'comment': { 'text': 'You\\'re such a tosser.' },\n",
        "  'requestedAttributes': {'TOXICITY': {}}\n",
        "}\n",
        "\n",
        "response = client.comments().analyze(body=analyze_request).execute()\n",
        "print(response)"
      ],
      "metadata": {
        "id": "2D1lOKlMTFpy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "876ad90f-26d3-4621-9866-70d86790b61f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 23, 'score': {'value': 0.95048624, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.95048624, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 21, 'score': {'value': 0.50789946, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.50789946, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. A \"You're such an asshole.\"\n",
        "This received a toxicity score of 0.95048624.\n",
        "Result: TOXIC\n",
        "1. B \"You're such a tosser.\"\n",
        "This received a toxicity score of 0.50789946. Result: TOXIC"
      ],
      "metadata": {
        "id": "bsiG-vjlm7xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_request = {\n",
        "  'comment': { 'text': 'What a complete idiot.' },\n",
        "  'requestedAttributes': {'TOXICITY': {}}\n",
        "}\n",
        "\n",
        "response = client.comments().analyze(body=analyze_request).execute()\n",
        "print(response)\n",
        "\n",
        "analyze_request = {\n",
        "  'comment': { 'text': 'What a complete wanker.' },\n",
        "  'requestedAttributes': {'TOXICITY': {}}\n",
        "}\n",
        "\n",
        "response = client.comments().analyze(body=analyze_request).execute()\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU-oXEvPndQY",
        "outputId": "3641fa30-984c-49ce-df3b-bcfc4839faac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 22, 'score': {'value': 0.8988238, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.8988238, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 23, 'score': {'value': 0.7510937, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.7510937, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. A \"What a complete idiot.\" This received a toxicity score of 0.8988238. Result: TOXIC\n",
        "2. B \"What a complete wanker.\" This received a toxicity score of 0.7510937. REesult: TOXIC"
      ],
      "metadata": {
        "id": "rvcrNLMankdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_request = {\n",
        "  'comment': { 'text': 'That makes you a thot.' },\n",
        "  'requestedAttributes': {'TOXICITY': {}}\n",
        "}\n",
        "\n",
        "response = client.comments().analyze(body=analyze_request).execute()\n",
        "print(response)\n",
        "\n",
        "analyze_request = {\n",
        "  'comment': { 'text': 'That makes you a slag.' },\n",
        "  'requestedAttributes': {'TOXICITY': {}}\n",
        "}\n",
        "\n",
        "response = client.comments().analyze(body=analyze_request).execute()\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwkkYWdLn4oq",
        "outputId": "3e8a4b24-e4ba-4524-d5a8-66b0e3c8794d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 22, 'score': {'value': 0.50503236, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.50503236, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 22, 'score': {'value': 0.37751234, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.37751234, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. A \"That makes you a thot.\" This received a toxicity score of 0.50503236. Result: TOXIC\n",
        "3. B \"That makes you a slag.\" This received a toxicity score of 0.37751234. Result: NON TOXIC"
      ],
      "metadata": {
        "id": "OGum3qDkoDfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_request = {\n",
        "  'comment': { 'text': 'I don\\'t know why you\\'re a dickhead.' },\n",
        "  'requestedAttributes': {'TOXICITY': {}}\n",
        "}\n",
        "\n",
        "response = client.comments().analyze(body=analyze_request).execute()\n",
        "print(response)\n",
        "\n",
        "analyze_request = {\n",
        "  'comment': { 'text': 'I don\\'t know why you\\'re a knob head' },\n",
        "  'requestedAttributes': {'TOXICITY': {}}\n",
        "}\n",
        "\n",
        "response = client.comments().analyze(body=analyze_request).execute()\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxIr4tVfooge",
        "outputId": "af7fedb9-134b-42c6-d7ad-2a6d0dc4f164"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 35, 'score': {'value': 0.911035, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.911035, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 35, 'score': {'value': 0.52272606, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.52272606, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. \"I don't know why you're a dickhead.\" This received a toxicity score of 0.911035. Result: TOXIC\n",
        "8. \"I don't know why you're a knob head.\" This received a toxicity score of 0.52272606. Result: TOXIC"
      ],
      "metadata": {
        "id": "d2MorBNNpBDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_request = {\n",
        "  'comment': { 'text': 'This proves you\\'re just a blue collar' },\n",
        "  'requestedAttributes': {'TOXICITY': {}}\n",
        "}\n",
        "\n",
        "response = client.comments().analyze(body=analyze_request).execute()\n",
        "print(response)\n",
        "\n",
        "analyze_request = {\n",
        "  'comment': { 'text': 'This proves you\\'re just a wazzock.' },\n",
        "  'requestedAttributes': {'TOXICITY': {}}\n",
        "}\n",
        "\n",
        "response = client.comments().analyze(body=analyze_request).execute()\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acdePIR6pVII",
        "outputId": "fc574dca-79ff-407a-8c3a-6000e72eb9f4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 37, 'score': {'value': 0.31963667, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.31963667, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 34, 'score': {'value': 0.4575469, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.4575469, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. \"This proves you're just a blue collar.\" This received a toxicity score of 0.31963667. Result: NOT TOXIC\n",
        "10. \"This proves you're just a wazzock.\" This received a toxicity score of 0/4575469. Result: NOT TOXIC"
      ],
      "metadata": {
        "id": "vhkTekoupuWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "My hypothesis was correct based on the samples I utilized. it was more likely to recognize the American terms as toxic and give it a higher rating despite the British terms being synonyms."
      ],
      "metadata": {
        "id": "4N3hdVWOqPKR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write about Results:"
      ],
      "metadata": {
        "id": "ytLyCzPzvjRU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this, I have learned that models cannot be assumed to account for diverse datasets. It's important to assess the model for any potential bias regarding slang words or terms from different age groups, subcultures, or regions of the world. I assumed that English language content would be the most tested for in this model, but it was clear from this test that American English is but not so much British English. I wasn't surprised from the overall results of these findings, but I didn't expect the difference to be as pronounced as it was.\n",
        "\n",
        "I theorize that this bias is based on the training data given to the model. I think it was trained on American information, so it struggled to recognize the British slang insults as toxic comments. I think this is a gap in the model\n",
        "\n",
        "Overall, the average is 0.717002 for the American sentences and 0.5233458 for the British sentences. This is a significant difference. Overall, two British returned as non-toxic and only one American sentence.\n",
        "\n",
        "Interestingly, one of the lowest American sentences included the word \"thot\" which might be because it's a lesser known slang word more common amoung generation z online users rather than older audiences who worked on the model."
      ],
      "metadata": {
        "id": "T-WhbmdXvleq"
      }
    }
  ]
}
